{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnames = []\n",
    "target_dir = test_dir\n",
    "dnames = [join(target_dir, dname) for dname in listdir(target_dir)]\n",
    "\n",
    "for dname in dnames:\n",
    "    \n",
    "    fnames =([join(dname, fname) for fname in listdir(dname)])\n",
    "    \n",
    "    cur_class = dname.split('\\\\')[-1]\n",
    "    print(cur_class, end=':- ')\n",
    "\n",
    "    NO_OF_FIG = 15\n",
    "    correct_predict_count = 0\n",
    "    high_accuracy_count = 0\n",
    "    \n",
    "    max_indices = []\n",
    "    wrong_class_list = []\n",
    "    \n",
    "    for index, img_path in enumerate(fnames):\n",
    "          \n",
    "        img = image.load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        \n",
    "        img_tensor = image.img_to_array(img)\n",
    "        img_tensor = img_tensor.reshape((1,) + img_tensor.shape)\n",
    "        img_tensor /= 255.\n",
    "        prediction = model.predict(img_tensor)[0]\n",
    "        \n",
    "        max_val = np.amax(prediction)\n",
    "        max_index = np.argmax(prediction)\n",
    "        \n",
    "        pred_class = CLASSES_TO_CLASSIFY[max_index]\n",
    "        \n",
    "        if pred_class == cur_class:         \n",
    "            correct_predict_count +=1\n",
    "        else:\n",
    "            wrong_class_list.append(pred_class)\n",
    "            \n",
    "        if max_val > 0.8:\n",
    "            high_accuracy_count += 1\n",
    "          \n",
    "    print('Accuracy: ' + str(correct_predict_count / len(fnames) * 100) + ' , High count: ' + str(high_accuracy_count))\n",
    "    print('\\n' + str(wrong_class_list) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnames = []\n",
    "target_dir = test_dir\n",
    "dnames = [join(target_dir, dname) for dname in listdir(target_dir)]\n",
    "\n",
    "for dname in dnames:\n",
    "    \n",
    "    fnames =([join(dname, fname) for fname in listdir(dname)])\n",
    "    \n",
    "    cur_class = dname.split('\\\\')[-1]\n",
    "    print(cur_class, end=':- ')\n",
    "\n",
    "    correct_predict_count = 0\n",
    "    high_accuracy_count = 0\n",
    "    \n",
    "    for index, img_path in enumerate(fnames):\n",
    "          \n",
    "        img = image.load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        \n",
    "        img_tensor = image.img_to_array(img)\n",
    "        img_tensor = img_tensor.reshape((1,) + img_tensor.shape)\n",
    "        img_tensor /= 255.\n",
    "        prediction = model.predict(img_tensor)[0]\n",
    "        \n",
    "        if cur_class == 'others':\n",
    "            if prediction[0] <= 0.5:\n",
    "                correct_predict_count +=1\n",
    "        else:\n",
    "            if prediction[0] > 0.5:\n",
    "                correct_predict_count +=1\n",
    "\n",
    "          \n",
    "    print('Accuracy: ' + str(correct_predict_count / len(fnames) * 100) + ' , High count: ' + str(high_accuracy_count))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Image.open(MAP_FILE_PATH) as im:\n",
    "    imgwidth, imgheight = im.size\n",
    "    SLICE_WIDTH, SLICE_HEIGHT = 256, 256\n",
    "    idx = 0\n",
    "    start_idx = 14000\n",
    "    delete_dir_files_helper(TEMP_SLICED_SUBDIR)\n",
    "    \n",
    "    for i in range(0, imgheight - SLICE_HEIGHT, SLICE_HEIGHT):\n",
    "        for j in range(0, imgwidth - SLICE_WIDTH, SLICE_WIDTH):\n",
    "            box = (j, i, j + SLICE_WIDTH, i + SLICE_HEIGHT)\n",
    "            try:\n",
    "                cropped_image = im.crop(box)\n",
    "                cropped_image.save(join(TEMP_SLICED_SUBDIR, 'image_{}.jpg'.format(start_idx + idx)), \"JPEG\", quality=100, optimize=True)\n",
    "                idx += 1\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                \n",
    "                pass\n",
    "    print('Saved ' + str(idx) + ' slices in ' + TEMP_SLICED_SUBDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict using data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#     test_generator = test_datagen.flow_from_directory(\n",
    "#         TEMP_SLICED_DIR,\n",
    "#         target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "#         batch_size=1,\n",
    "#         save_prefix='slices',\n",
    "#         save_format='jpeg',\n",
    "#         shuffle=False,\n",
    "#         save_to_dir=AUG_DIR,\n",
    "#         class_mode=None)\n",
    "    \n",
    "#     predictions = model.predict_generator(test_generator, no_of_samples , max_queue_size=1, workers=5, use_multiprocessing=False, verbose=1)\n",
    "#     print(predictions.shape)\n",
    "#     print(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class_overlay(prediction):\n",
    "    \n",
    "    if prediction > 0.4:\n",
    "        return (0, 255, 0, 100)\n",
    "    else:\n",
    "        return (0, 255, 0, 0)\n",
    "\n",
    "\n",
    "with Image.open(MAP_FILE_PATH) as map_image:\n",
    "       \n",
    "    no_of_samples = len(listdir(TEMP_SLICED_SUBDIR))\n",
    "    MODEL_PATH =  join(MODEL_DIR, 'roads_binary_classifer_model.h5');\n",
    "    \n",
    "    imgwidth, imgheight = map_image.size\n",
    "    idx = 0\n",
    "    \n",
    "    model = load_model(MODEL_PATH)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        TEMP_SLICED_DIR,\n",
    "        target_size=(SLICE_WIDTH, SLICE_HEIGHT),\n",
    "        batch_size=1,\n",
    "        save_format='jpeg',\n",
    "        save_to_dir=AUG_DIR,\n",
    "        shuffle=False,\n",
    "        class_mode=None)\n",
    "\n",
    "    predictions = model.predict_generator(test_generator, no_of_samples, max_queue_size=10, workers=8, use_multiprocessing=False, verbose=0)\n",
    "    predictions = np.asarray(predictions).flatten()\n",
    "  \n",
    "    for i in range(0, imgheight , SLICE_HEIGHT):\n",
    "        x_offset = 0\n",
    "        for j in range(0, imgwidth , SLICE_WIDTH):\n",
    "            box = (j, i, j + SLICE_WIDTH, i + SLICE_HEIGHT)\n",
    "            try:\n",
    "                \n",
    "                overlay_color = predict_class_overlay(predictions[idx])\n",
    "                overlay = Image.new('RGBA', ( SLICE_WIDTH, SLICE_HEIGHT), overlay_color)  \n",
    "                map_image.paste(overlay, (j, i), overlay)\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                pass\n",
    "            idx +=1\n",
    "      \n",
    "    map_image.save(join(OUTPUT_DIR, 'binary_class_map_output.jpg'), \"JPEG\", quality=100, optimize=True)\n",
    "    plt.figure(figsize=(30, 30)) \n",
    "    plt.imshow(map_image)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
